import multiprocessing
import time
import pyautogui
import cv2
import numpy as np
import pynput
from random import randint

def autoscan(stop_event, should_stop):
    time.sleep(1.5)

    # Get the screen size
    screen_width, screen_height = pyautogui.size()

    # Set the boundary size
    boundary_width = 500
    boundary_height = 300

    # Calculate the starting position
    start_x = (screen_width - boundary_width) / 2
    start_y = (screen_height - boundary_height) / 2 - 200

    # Set the speed of the mouse movement
    speed = 28

    # Set the amount to move the mouse down after each row
    move_down = 8

    # Loop through each row
    for row in range(int(boundary_height / speed)):
        # Move the mouse from left to right
        for x in range(int(boundary_width / speed)):
            pyautogui.moveTo(start_x + x * speed, start_y + row * speed, duration=0.1)

            if should_stop.value:  # Check if the autoscan process should stop
                break
        if should_stop.value:  # Check if the autoscan process should stop
            break

        # Move the mouse down after each row
        start_y += move_down

    if not stop_event.is_set():
        return

def cursor_change(stop_event, should_stop):

    start_time = time.time()  # Record the start time
    time.sleep(2)
    while not stop_event.is_set():
        # Load the reference image
        reference = cv2.imread(r"C:\Users\User\PycharmProjects\pythonProject\wowhand.png", cv2.IMREAD_GRAYSCALE)

        # Create a binary mask that represents the cursor shape
        _, mask = cv2.threshold(reference, 0, 255, cv2.THRESH_BINARY)

        while True:
            # Get the current position of the mouse cursor
            x, y = pyautogui.position()

            # Take a screenshot of the area around the cursor
            screenshot = np.array(pyautogui.screenshot(region=(x - 7, y - 8, 50, 50)))

            # Convert the screenshot to grayscale
            screenshot = cv2.cvtColor(screenshot, cv2.COLOR_BGR2GRAY)

            # Resize the screenshot to the same size as the reference image
            screenshot = cv2.resize(screenshot, (60, 60))

            # Crop the screenshot to a smaller region that only contains the cursor
            non_zero = cv2.findNonZero(mask)
            x, y, w, h = cv2.boundingRect(non_zero)
            screenshot = screenshot[y:y + h, x:x + w]

            # Threshold the screenshot to remove the background pixels
            _, screenshot = cv2.threshold(screenshot, 0, 200, cv2.THRESH_BINARY)
            _, reference = cv2.threshold(reference, 40, 200, cv2.THRESH_BINARY)

            # Apply the binary mask to the reference image
            reference = cv2.bitwise_and(reference, reference, mask=mask)

            # Use matchTemplate to compare the screenshot and the reference image
            result = cv2.matchTemplate(screenshot, reference, cv2.TM_CCOEFF_NORMED)

            # Check if the result is above a certain threshold
            threshold = 0.1
            loc = np.where(result >= threshold)

            # Check if the time limit has been reached
            if time.time() - start_time >= 25:
                print("30-second time limit reached")
                return


            if len(loc[0]) > 0:
                continue
            else:
                should_stop.value = True  # Set the flag to stop the autoscan process
                return

def monitor_area(stop_event, should_stop):
    start_time = time.time()  # Record the start time

    while not stop_event.is_set():
        # Define the screenshot size
        size = (60, 60)

        # Set the threshold for movement detection in pixels
        threshold = 400

        # Monitor the segmented image for changes
        while True:

            # Get the mouse and keyboard controllers
            mouse = pynput.mouse.Controller()
            keyboard = pynput.keyboard.Controller()

            # Get the current mouse position
            x, y = pyautogui.position()

            # Take a screenshot at the mouse position
            screenshot = pyautogui.screenshot(region=(x - size[0] // 2, y - size[1] // 2, size[0], size[1]))

            # Convert the screenshot to grayscale
            gray = cv2.cvtColor(np.array(screenshot), cv2.COLOR_RGB2GRAY)

            # Fine-tune the dark and bright pixels using adaptive thresholding
            thresh = cv2.adaptiveThreshold(gray, 245, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)

            # Find the contours in the thresholded image
            contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            # If there are any contours, find the largest one
            if len(contours) > 0:
                largest_contour = max(contours, key=cv2.contourArea)

                # Create a mask for the largest contour
                mask = np.zeros_like(thresh)
                cv2.drawContours(mask, [largest_contour], 0, 255, -1)

                # If this is not the first frame, compare the new mask to the previous mask
                if 'prev_mask' in locals():
                    # Calculate the absolute difference between the masks
                    diff = cv2.absdiff(mask, prev_mask)

                    # Count the number of white pixels in the difference image
                    count = np.count_nonzero(diff)

                    # If enough pixels have moved, print "movement detected"
                    if count >= threshold:
                        print("Collecting your fish...")
                        keyboard.press(pynput.keyboard.Key.shift)
                        time.sleep(1)
                        mouse.click(pynput.mouse.Button.right, 1)
                        keyboard.release(pynput.keyboard.Key.shift)
                        delay = randint(2, 5)
                        print("Recasting Fishing Line... " + str(delay) + "s")
                        time.sleep(delay)
                        should_stop.value = True
                        return

                # Store the current mask for comparison in the next frame
                prev_mask = mask

        # Check if the time limit has been reached
            if time.time() - start_time >= 27:
                print("30-second time limit reached")
                return

if __name__ == '__main__':
    while True:
        stop_event = multiprocessing.Event()
        should_stop = multiprocessing.Value('b', False)  # Create a shared value to indicate whether the autoscan process should stop

        # Get the mouse and keyboard controllers
        mouse = pynput.mouse.Controller()
        keyboard = pynput.keyboard.Controller()

        print("Fishing started, Goodluck!")
        keyboard.press('1')
        keyboard.release('1')

        autoscan_process = multiprocessing.Process(target=autoscan, args=(stop_event, should_stop))
        cursor_change_process = multiprocessing.Process(target=cursor_change, args=(stop_event, should_stop))

        autoscan_process.start()
        cursor_change_process.start()

        cursor_change_process.join()  # Wait for cursor_change to complete and set stop_event
        autoscan_process.join()  # Wait for autoscan to complete


        monitor_area_process = multiprocessing.Process(target=monitor_area, args=(stop_event, should_stop))
        monitor_area_process.start()  # Start monitor_area once autoscan and cursor change have finished

        monitor_area_process.join()  # Wait for monitor_area to complete


        time.sleep(1)
